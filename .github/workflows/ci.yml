name: CI/CD Pipeline

# This workflow defines a complete CI/CD pipeline for the Java Spring Boot application
# It runs on push and pull requests to main/master branches

on:
  push:
    branches: [ master, main ]
  pull_request:
    branches: [ master, main ]

permissions:
  contents: read
  packages: write

# Environment variables used across all jobs
env:
  IMAGE_TAG_PATIENT: ghcr.io/${{ github.repository_owner }}/patient-service:${{ github.sha }}
  IMAGE_TAG_DOCTOR: ghcr.io/${{ github.repository_owner }}/doctor-service:${{ github.sha }}
  REGISTRY: ghcr.io
  STAGING_NAMESPACE: medinsight-staging
  PROD_NAMESPACE: medinsight-prod
  APP_PORT_PATIENT: 8050
  APP_PORT_DOCTOR: 8082
  NODE_PORT_STAGING_PATIENT: "30080"
  NODE_PORT_STAGING_DOCTOR: "30081"
  NODE_PORT_PROD_PATIENT: "30082"
  NODE_PORT_PROD_DOCTOR: "30083"

jobs:
  # Job 1: Pre-check - Secret detection using Gitleaks
  # Scans the codebase for accidentally committed secrets (API keys, passwords, etc.)
  precheck:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history needed for proper secret scanning

      - name: Gitleaks - secrets detection
        # Run Gitleaks to detect any leaked secrets in the repository
        # Uses --no-git to scan files directly, --exit-code 0 to not fail on findings
        run: |
          docker run --rm -v $(pwd):/src zricethezav/gitleaks:latest detect \
            --source /src \
            --no-git \
            --report-format json \
            --report-path /src/gitleaks.json \
            --exit-code 0 || true
          [ -s gitleaks.json ] || echo "[]" > gitleaks.json

      - name: Display Gitleaks report
        # Show the contents of the report in the workflow logs
        run: |
          if [ -f gitleaks.json ]; then
            cat gitleaks.json
          else
            echo "No gitleaks report generated"
          fi

      - name: Upload Gitleaks report
        # Save the report as an artifact for later review
        uses: actions/upload-artifact@v4
        with:
          name: gitleaks-report
          path: gitleaks.json
        if: always()

  # Job 2: Scan - Security and code quality analysis
  # Performs SAST (Static Application Security Testing) with SonarQube
  # and SCA (Software Composition Analysis) with Snyk
  scan:
    runs-on: ubuntu-latest
    needs: precheck  # Wait for precheck to complete
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up JDK 17
        uses: actions/setup-java@v4
        with:
          java-version: '17'
          distribution: 'temurin'
          cache: maven

      - name: Build with Maven (compile classes for SonarCloud)
        run: |
          cd medinsight-project-main/services/patient-service
          mvn clean compile -DskipTests
          cd ../doctor-service
          mvn clean compile -DskipTests

      - name: SonarQube (SAST)
        # Static code analysis to find bugs, vulnerabilities, and code smells
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_ORG: ${{ secrets.SONAR_ORGANIZATION }}
          SONAR_KEY: ${{ secrets.SONAR_PROJECT_KEY }}
          SONAR_URL: ${{ secrets.SONAR_HOST_URL }}
        run: |
          echo "üîç Running SonarCloud analysis..."
          
          if [ -z "$SONAR_TOKEN" ] || [ -z "$SONAR_ORG" ] || [ -z "$SONAR_KEY" ]; then
            echo "‚ùå Missing required SonarCloud secrets!"
            exit 1
          fi
          
          docker run --rm -v $(pwd):/usr/src \
            -e SONAR_TOKEN=$SONAR_TOKEN \
            sonarsource/sonar-scanner-cli:latest \
            -Dsonar.projectKey=$SONAR_KEY \
            -Dsonar.organization=$SONAR_ORG \
            -Dsonar.host.url=${SONAR_URL:-https://sonarcloud.io} \
            -Dsonar.sources=medinsight-project-main/services \
            -Dsonar.java.binaries=medinsight-project-main/services/patient-service/target/classes,medinsight-project-main/services/doctor-service/target/classes \
            -Dsonar.java.source=17 \
            -Dsonar.java.target=17 \
            -Dsonar.exclusions=**/test/**
        continue-on-error: true

      - name: Snyk (SCA)
        # Scan dependencies for known vulnerabilities
        run: |
          touch snyk-report.json
          docker run --rm -v $(pwd):/src \
            -e SNYK_TOKEN=${{ secrets.SNYK_TOKEN }} \
            snyk/snyk:maven-3-jdk-17 sh -c "cd /src/medinsight-project-main && snyk auth \$SNYK_TOKEN && snyk test --all-projects --json > /src/snyk-report.json" || true
        continue-on-error: true

      - name: Upload Snyk report
        uses: actions/upload-artifact@v4
        with:
          name: snyk-report
          path: snyk-report.json
        if: always()

  # Job 3: Build - Build Docker images for both services
  # Creates containerized versions of patient-service and doctor-service
  build:
    runs-on: ubuntu-latest
    needs: scan  # Wait for security scans to complete
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        # Enable advanced Docker build features
        uses: docker/setup-buildx-action@v3

      - name: Build patient-service Docker image
        # Build and export the patient service image as a tar file
        uses: docker/build-push-action@v5
        with:
          context: ./medinsight-project-main/services/patient-service
          tags: ${{ env.IMAGE_TAG_PATIENT }}, patient-local:latest
          outputs: type=docker,dest=patient-docker-image.tar

      - name: Build doctor-service Docker image
        # Build and export the doctor service image as a tar file
        uses: docker/build-push-action@v5
        with:
          context: ./medinsight-project-main/services/doctor-service
          tags: ${{ env.IMAGE_TAG_DOCTOR }}, doctor-local:latest
          outputs: type=docker,dest=doctor-docker-image.tar

      - name: Upload patient Docker image artifact
        # Save the image for use in subsequent jobs
        uses: actions/upload-artifact@v4
        with:
          name: patient-docker-image
          path: patient-docker-image.tar

      - name: Upload doctor Docker image artifact
        uses: actions/upload-artifact@v4
        with:
          name: doctor-docker-image
          path: doctor-docker-image.tar

  # Job 4: Image-scan - Scan Docker images for vulnerabilities using Trivy
  # Checks for HIGH and CRITICAL vulnerabilities in the container images
  image-scan:
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download patient Docker image
        uses: actions/download-artifact@v4
        with:
          name: patient-docker-image
          path: .

      - name: Download doctor Docker image
        uses: actions/download-artifact@v4
        with:
          name: doctor-docker-image
          path: .

      - name: Load patient Docker image
        # Load the image into Docker daemon for scanning
        run: docker load < patient-docker-image.tar

      - name: Load doctor Docker image
        run: docker load < doctor-docker-image.tar

      - name: Trivy scan patient-service
        # Scan for vulnerabilities in the patient service container
        run: |
          docker run --rm -v $(pwd):/reports aquasec/trivy:latest image patient-local:latest --format json --output /reports/trivy-patient-report.json --severity HIGH,CRITICAL || true

      - name: Trivy scan doctor-service
        # Scan for vulnerabilities in the doctor service container
        run: |
          docker run --rm -v $(pwd):/reports aquasec/trivy:latest image doctor-local:latest --format json --output /reports/trivy-doctor-report.json --severity HIGH,CRITICAL || true

      - name: Check Trivy results for patient-service
        # Parse results and fail if CRITICAL vulnerabilities are found
        run: |
          if [ -f trivy-patient-report.json ]; then
            cat trivy-patient-report.json
            CRITICAL=$(jq '[.[]?.Vulnerabilities[]? | select(.Severity=="CRITICAL")] | length' trivy-patient-report.json || echo 0)
            echo "CRITICAL vulns in patient-service: $CRITICAL"
            if [ "$CRITICAL" -gt 0 ]; then
              echo "‚ùå CRITICAL vulnerabilities detected in patient-service. Failing pipeline."
              exit 1
            fi
          else
            echo "No trivy report for patient-service"
          fi

      - name: Check Trivy results for doctor-service
        run: |
          if [ -f trivy-doctor-report.json ]; then
            cat trivy-doctor-report.json
            CRITICAL=$(jq '[.[]?.Vulnerabilities[]? | select(.Severity=="CRITICAL")] | length' trivy-doctor-report.json || echo 0)
            echo "CRITICAL vulns in doctor-service: $CRITICAL"
            if [ "$CRITICAL" -gt 0 ]; then
              echo "‚ùå CRITICAL vulnerabilities detected in doctor-service. Failing pipeline."
              exit 1
            fi
          else
            echo "No trivy report for doctor-service"
          fi

      - name: Upload Trivy patient report
        uses: actions/upload-artifact@v4
        with:
          name: trivy-patient-report
          path: trivy-patient-report.json
        if: always()

      - name: Upload Trivy doctor report
        uses: actions/upload-artifact@v4
        with:
          name: trivy-doctor-report
          path: trivy-doctor-report.json
        if: always()

  # Job 5: Push - Push Docker images to GitHub Container Registry
  # Only runs on main/master branch (not on PRs)
  push:
    runs-on: ubuntu-latest
    needs: image-scan
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    permissions:
      packages: write
      contents: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download patient Docker image
        uses: actions/download-artifact@v4
        with:
          name: patient-docker-image
          path: .

      - name: Download doctor Docker image
        uses: actions/download-artifact@v4
        with:
          name: doctor-docker-image
          path: .

      - name: Load patient Docker image
        run: docker load < patient-docker-image.tar

      - name: Load doctor Docker image
        run: docker load < doctor-docker-image.tar

      - name: Tag patient image
        # Tag with the full GHCR path including commit SHA
        run: docker tag patient-local:latest ${{ env.IMAGE_TAG_PATIENT }}

      - name: Tag doctor image
        run: docker tag doctor-local:latest ${{ env.IMAGE_TAG_DOCTOR }}

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GHCR_PAT }}

      - name: Push patient image
        run: docker push ${{ env.IMAGE_TAG_PATIENT }}

      - name: Push doctor image
        run: docker push ${{ env.IMAGE_TAG_DOCTOR }}

  # Job 6: Deploy to staging - Deploy to staging environment
  # Uses kubectl to deploy to Kubernetes cluster
  deploy-to-staging:
    runs-on: ubuntu-latest
    needs: push
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    environment: staging  # GitHub environment for staging (can have protection rules)
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: v1.29.0

      - name: Configure kubeconfig
        # Decode and setup kubeconfig from secret
        env:
          KUBECONFIG_DATA: ${{ secrets.KUBECONFIG_DATA }}
        run: |
          mkdir -p ~/.kube
          echo "$KUBECONFIG_DATA" | base64 -d > ~/.kube/config
          kubectl cluster-info
          kubectl get nodes

      - name: Create staging namespace if not exists
        run: |
          kubectl create namespace ${{ env.STAGING_NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -

      - name: Create GHCR pull secret
        env:
          GHCR_PAT: ${{ secrets.GHCR_PAT }}
        run: |
          kubectl delete secret ghcr-secret -n ${{ env.STAGING_NAMESPACE }} --ignore-not-found
          kubectl create secret docker-registry ghcr-secret \
            --namespace=${{ env.STAGING_NAMESPACE }} \
            --docker-server=ghcr.io \
            --docker-username=${{ github.actor }} \
            --docker-password=$GHCR_PAT

      - name: Clean old database resources
        env:
          NAMESPACE: ${{ env.STAGING_NAMESPACE }}
        run: |
          echo "üßπ Cleaning old database resources..."
          # Delete deployments first (stops pods using PVCs)
          kubectl delete deployment patient-db -n $NAMESPACE --ignore-not-found --timeout=60s || true
          kubectl delete deployment doctor-db -n $NAMESPACE --ignore-not-found --timeout=60s || true
          # Wait for pods to terminate
          kubectl wait --for=delete pod -l app=patient-db -n $NAMESPACE --timeout=60s || true
          kubectl wait --for=delete pod -l app=doctor-db -n $NAMESPACE --timeout=60s || true
          # Now delete PVCs (no longer in use)
          kubectl delete pvc patient-db-pvc -n $NAMESPACE --ignore-not-found --timeout=30s || true
          kubectl delete pvc doctor-db-pvc -n $NAMESPACE --ignore-not-found --timeout=30s || true
          # Finally delete PVs
          kubectl delete pv patient-db-pv-$NAMESPACE --ignore-not-found --timeout=30s || true
          kubectl delete pv doctor-db-pv-$NAMESPACE --ignore-not-found --timeout=30s || true
          echo "‚úÖ Cleanup complete"

      - name: Deploy databases
        env:
          NAMESPACE: ${{ env.STAGING_NAMESPACE }}
        run: |
          echo "üóÑÔ∏è Deploy patient-db"
          envsubst < k8s/patient-db.yaml | kubectl apply -n $NAMESPACE -f -
          echo "üóÑÔ∏è Deploy doctor-db"
          envsubst < k8s/doctor-db.yaml | kubectl apply -n $NAMESPACE -f -
          echo "‚è≥ Waiting for databases to be ready..."
          kubectl rollout status deployment/patient-db -n $NAMESPACE --timeout=3m
          kubectl rollout status deployment/doctor-db -n $NAMESPACE --timeout=3m
          sleep 10

      - name: Deploy to staging
        # Apply Kubernetes manifests with environment variable substitution
        env:
          NAMESPACE: ${{ env.STAGING_NAMESPACE }}
          IMAGE_TAG_PATIENT: ${{ env.IMAGE_TAG_PATIENT }}
          IMAGE_TAG_DOCTOR: ${{ env.IMAGE_TAG_DOCTOR }}
          APP_PORT_PATIENT: ${{ env.APP_PORT_PATIENT }}
          APP_PORT_DOCTOR: ${{ env.APP_PORT_DOCTOR }}
          NODE_PORT_PATIENT: ${{ env.NODE_PORT_STAGING_PATIENT }}
          NODE_PORT_DOCTOR: ${{ env.NODE_PORT_STAGING_DOCTOR }}
        run: |
          echo "üßπ Clean old service deployments..."
          kubectl delete deployment patient-service -n $NAMESPACE --ignore-not-found --timeout=60s || true
          kubectl delete deployment doctor-service -n $NAMESPACE --ignore-not-found --timeout=60s || true
          kubectl wait --for=delete pod -l app=patient-service -n $NAMESPACE --timeout=60s || true
          kubectl wait --for=delete pod -l app=doctor-service -n $NAMESPACE --timeout=60s || true
          echo "üöÄ Deploy patient-service"
          envsubst < k8s/patient-deployment.yaml | kubectl apply -n $NAMESPACE -f -
          envsubst < k8s/patient-service.yaml | kubectl apply -n $NAMESPACE -f -
          echo "üöÄ Deploy doctor-service"
          envsubst < k8s/doctor-deployment.yaml | kubectl apply -n $NAMESPACE -f -
          envsubst < k8s/doctor-service.yaml | kubectl apply -n $NAMESPACE -f -
          echo "‚è≥ Waiting for rollout..."
          kubectl rollout status deployment/patient-service -n $NAMESPACE --timeout=5m
          kubectl rollout status deployment/doctor-service -n $NAMESPACE --timeout=5m

  # Job 7: Security-scan - Dynamic security scan with OWASP ZAP
  # Performs DAST (Dynamic Application Security Testing) against the staging environment
  security-scan:
    runs-on: ubuntu-latest
    needs: deploy-to-staging
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup kubectl for port-forward
        uses: azure/setup-kubectl@v4
        with:
          version: v1.29.0

      - name: Configure kubeconfig
        env:
          KUBECONFIG_DATA: ${{ secrets.KUBECONFIG_DATA }}
        run: |
          mkdir -p ~/.kube
          echo "$KUBECONFIG_DATA" | base64 -d > ~/.kube/config

      - name: Port forward and run OWASP ZAP scan
        # Forward the staging service port and run ZAP baseline scan
        run: |
          echo "üîç Starting port-forward..."
          kubectl port-forward -n ${{ env.STAGING_NAMESPACE }} svc/patient-service 8080:${{ env.APP_PORT_PATIENT }} &
          FORWARD_PID=$!
          
          sleep 5
          
          echo "üì¶ Pulling ZAP image..."
          docker pull ghcr.io/zaproxy/zaproxy:stable
          
          echo "üöÄ Starting ZAP scan..."
          docker run --rm \
            --network host \
            -v $(pwd):/zap/wrk/:rw \
            ghcr.io/zaproxy/zaproxy:stable zap-baseline.py \
            -t "http://localhost:8080" \
            -m 10 \
            -r zap_report.html \
            -J zap_report.json || true
          
          kill $FORWARD_PID || true

      - name: Upload ZAP reports
        uses: actions/upload-artifact@v4
        with:
          name: zap-reports
          path: zap_report.*
        if: always()

  # Job 8: Promote to prod - Deploy to production (requires manual approval)
  # This job uses the 'production' environment which should have protection rules configured
  promote-to-prod:
    runs-on: ubuntu-latest
    needs: security-scan
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    environment: production  # GitHub environment with manual approval required
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: v1.29.0

      - name: Configure kubeconfig
        env:
          KUBECONFIG_DATA: ${{ secrets.KUBECONFIG_DATA }}
        run: |
          mkdir -p ~/.kube
          echo "$KUBECONFIG_DATA" | base64 -d > ~/.kube/config

      - name: Create prod namespace if not exists
        run: |
          kubectl create namespace ${{ env.PROD_NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -

      - name: Create GHCR pull secret for production
        env:
          GHCR_PAT: ${{ secrets.GHCR_PAT }}
        run: |
          kubectl delete secret ghcr-secret -n ${{ env.PROD_NAMESPACE }} --ignore-not-found
          kubectl create secret docker-registry ghcr-secret \
            --namespace=${{ env.PROD_NAMESPACE }} \
            --docker-server=ghcr.io \
            --docker-username=${{ github.actor }} \
            --docker-password=$GHCR_PAT

      - name: Clean old database resources in production
        env:
          NAMESPACE: ${{ env.PROD_NAMESPACE }}
        run: |
          echo "üßπ Cleaning old database resources..."
          # Delete deployments first (stops pods using PVCs)
          kubectl delete deployment patient-db -n $NAMESPACE --ignore-not-found --timeout=60s || true
          kubectl delete deployment doctor-db -n $NAMESPACE --ignore-not-found --timeout=60s || true
          # Wait for pods to terminate
          kubectl wait --for=delete pod -l app=patient-db -n $NAMESPACE --timeout=60s || true
          kubectl wait --for=delete pod -l app=doctor-db -n $NAMESPACE --timeout=60s || true
          # Now delete PVCs (no longer in use)
          kubectl delete pvc patient-db-pvc -n $NAMESPACE --ignore-not-found --timeout=30s || true
          kubectl delete pvc doctor-db-pvc -n $NAMESPACE --ignore-not-found --timeout=30s || true
          # Finally delete PVs
          kubectl delete pv patient-db-pv-$NAMESPACE --ignore-not-found --timeout=30s || true
          kubectl delete pv doctor-db-pv-$NAMESPACE --ignore-not-found --timeout=30s || true
          echo "‚úÖ Cleanup complete"

      - name: Deploy databases to production
        env:
          NAMESPACE: ${{ env.PROD_NAMESPACE }}
        run: |
          echo "üóÑÔ∏è Deploy patient-db to production"
          envsubst < k8s/patient-db.yaml | kubectl apply -n $NAMESPACE -f -
          echo "üóÑÔ∏è Deploy doctor-db to production"
          envsubst < k8s/doctor-db.yaml | kubectl apply -n $NAMESPACE -f -
          echo "‚è≥ Waiting for databases to be ready..."
          kubectl rollout status deployment/patient-db -n $NAMESPACE --timeout=3m
          kubectl rollout status deployment/doctor-db -n $NAMESPACE --timeout=3m
          sleep 10

      - name: Deploy to production
        # Apply the same manifests to production namespace
        env:
          NAMESPACE: ${{ env.PROD_NAMESPACE }}
          IMAGE_TAG_PATIENT: ${{ env.IMAGE_TAG_PATIENT }}
          IMAGE_TAG_DOCTOR: ${{ env.IMAGE_TAG_DOCTOR }}
          APP_PORT_PATIENT: ${{ env.APP_PORT_PATIENT }}
          APP_PORT_DOCTOR: ${{ env.APP_PORT_DOCTOR }}
          NODE_PORT_PATIENT: ${{ env.NODE_PORT_PROD_PATIENT }}
          NODE_PORT_DOCTOR: ${{ env.NODE_PORT_PROD_DOCTOR }}
        run: |
          echo "üßπ Clean old service deployments..."
          kubectl delete deployment patient-service -n $NAMESPACE --ignore-not-found --timeout=60s || true
          kubectl delete deployment doctor-service -n $NAMESPACE --ignore-not-found --timeout=60s || true
          kubectl wait --for=delete pod -l app=patient-service -n $NAMESPACE --timeout=60s || true
          kubectl wait --for=delete pod -l app=doctor-service -n $NAMESPACE --timeout=60s || true
          echo "üöÄ Deploy patient-service to production"
          envsubst < k8s/patient-deployment.yaml | kubectl apply -n $NAMESPACE -f -
          envsubst < k8s/patient-service.yaml | kubectl apply -n $NAMESPACE -f -
          echo "üöÄ Deploy doctor-service to production"
          envsubst < k8s/doctor-deployment.yaml | kubectl apply -n $NAMESPACE -f -
          envsubst < k8s/doctor-service.yaml | kubectl apply -n $NAMESPACE -f -
          echo "‚è≥ Waiting for rollout..."
          kubectl rollout status deployment/patient-service -n $NAMESPACE --timeout=5m
          kubectl rollout status deployment/doctor-service -n $NAMESPACE --timeout=5m

      - name: Create production info artifact
        # Generate a summary file with deployment information
        run: |
          cat > service_info.env <<EOF
          PATIENT_SERVICE_URL=http://$(kubectl get svc patient-service -n ${{ env.PROD_NAMESPACE }} -o jsonpath='{.spec.clusterIP}'):${{ env.APP_PORT_PATIENT }}
          DOCTOR_SERVICE_URL=http://$(kubectl get svc doctor-service -n ${{ env.PROD_NAMESPACE }} -o jsonpath='{.spec.clusterIP}'):${{ env.APP_PORT_DOCTOR }}
          DEPLOYMENT_TIME=$(date -u +'%Y-%m-%dT%H:%M:%SZ')
          DEPLOYMENT_COMMIT=${{ github.sha }}
          EOF

      - name: Upload service info
        uses: actions/upload-artifact@v4
        with:
          name: prod-service-info
          path: service_info.env