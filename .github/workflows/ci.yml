name: CI/CD Pipeline

# Cette section d√©finit les d√©clencheurs (Triggers)
on:
  push:
    branches: [ master, main ]
  pull_request:
    branches: [ master, main ]

permissions:
  contents: read
  packages: write

# Variables d'environnement globales pour les tags d'images et ports
env:
  IMAGE_TAG_PATIENT: ghcr.io/${{ github.repository_owner }}/patient-service:${{ github.sha }}
  IMAGE_TAG_DOCTOR: ghcr.io/${{ github.repository_owner }}/doctor-service:${{ github.sha }}
  REGISTRY: ghcr.io
  STAGING_NAMESPACE: medinsight-staging
  PROD_NAMESPACE: medinsight-prod
  APP_PORT_PATIENT: 8050
  APP_PORT_DOCTOR: 8082
  NODE_PORT_STAGING_PATIENT: "30080"
  NODE_PORT_STAGING_DOCTOR: "30081"
  NODE_PORT_PROD_PATIENT: "30082"
  NODE_PORT_PROD_DOCTOR: "30083"

jobs:
  # JOB 1 : D√©tection de secrets avec Gitleaks
  precheck:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # N√©cessaire pour analyser l'historique complet

      - name: Gitleaks - secrets detection
        run: |
          docker run --rm -v $(pwd):/src zricethezav/gitleaks:latest detect \
            --source /src \
            --no-git \
            --report-format json \
            --report-path /src/gitleaks.json \
            --exit-code 0 || true
          [ -s gitleaks.json ] || echo "[]" > gitleaks.json

      - name: Display Gitleaks report
        run: |
          if [ -f gitleaks.json ]; then
            cat gitleaks.json
          else
            echo "No gitleaks report generated"
          fi

      - name: Upload Gitleaks report
        uses: actions/upload-artifact@v4
        with:
          name: gitleaks-report
          path: gitleaks.json
        if: always()

  # JOB 2 : Analyse de qualit√© (SAST avec SonarQube et SCA avec Snyk)
  scan:
    runs-on: ubuntu-latest
    needs: precheck
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up JDK 17
        uses: actions/setup-java@v4
        with:
          java-version: '17'
          distribution: 'temurin'
          cache: maven

      - name: Build with Maven (compile classes for SonarCloud)
        run: |
          cd medinsight-project-main/services/patient-service
          mvn clean compile -DskipTests
          cd ../doctor-service
          mvn clean compile -DskipTests

      - name: SonarQube (SAST)
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_ORG: ${{ secrets.SONAR_ORGANIZATION }}
          SONAR_KEY: ${{ secrets.SONAR_PROJECT_KEY }}
          SONAR_URL: ${{ secrets.SONAR_HOST_URL }}
        run: |
          echo "üîç Running SonarCloud analysis..."
          if [ -z "$SONAR_TOKEN" ] || [ -z "$SONAR_ORG" ] || [ -z "$SONAR_KEY" ]; then
            echo "‚ùå Missing required SonarCloud secrets!"
            exit 1
          fi
          docker run --rm -v $(pwd):/usr/src \
            -e SONAR_TOKEN=$SONAR_TOKEN \
            sonarsource/sonar-scanner-cli:latest \
            -Dsonar.projectKey=$SONAR_KEY \
            -Dsonar.organization=$SONAR_ORG \
            -Dsonar.host.url=${SONAR_URL:-https://sonarcloud.io} \
            -Dsonar.sources=medinsight-project-main/services \
            -Dsonar.java.binaries=medinsight-project-main/services/patient-service/target/classes,medinsight-project-main/services/doctor-service/target/classes \
            -Dsonar.java.source=17 \
            -Dsonar.java.target=17 \
            -Dsonar.exclusions=**/test/**
        continue-on-error: true

      - name: List files for Snyk debug
        run: |
          ls -lR medinsight-project-main

      - name: Print SNYK_TOKEN length
        run: |
          echo "${{ secrets.SNYK_TOKEN }}" | wc -c


      - name: Debug Snyk Auth
        run: |
          docker run --rm -v $(pwd):/src -e SNYK_TOKEN=${{ secrets.SNYK_TOKEN }} snyk/snyk:maven-3-jdk-17 sh -c "snyk auth \$SNYK_TOKEN"

      - name: Prepare reports directory
        run: mkdir -p reports

      - name: Snyk test patient-service
        run: |
          docker run --rm -v $(pwd):/src -e SNYK_TOKEN=${{ secrets.SNYK_TOKEN }} snyk/snyk:maven-3-jdk-17 \
            sh -c "cd /src/medinsight-project-main/services/patient-service && snyk test --file=pom.xml --json > /src/reports/snyk-patient-report.json"
          [ -s reports/snyk-patient-report.json ] || echo '{}' > reports/snyk-patient-report.json

      - name: List Snyk report files
        run: ls -lh reports

      - name: Upload Snyk report
        uses: actions/upload-artifact@v4
        with:
          name: snyk-patient-report
          path: reports/snyk-patient-report.json
        if: always()

      - name: Upload Snyk report
        uses: actions/upload-artifact@v4
        with:
          name: snyk-report
          path: snyk-report.json
        if: always()

  # JOB 3 : Construction des images Docker pour les deux services
  build:
    runs-on: ubuntu-latest
    needs: scan
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build patient-service Docker image
        uses: docker/build-push-action@v5
        with:
          context: ./medinsight-project-main/services/patient-service
          tags: ${{ env.IMAGE_TAG_PATIENT }}, patient-local:latest
          outputs: type=docker,dest=patient-docker-image.tar

      - name: Build doctor-service Docker image
        uses: docker/build-push-action@v5
        with:
          context: ./medinsight-project-main/services/doctor-service
          tags: ${{ env.IMAGE_TAG_DOCTOR }}, doctor-local:latest
          outputs: type=docker,dest=doctor-docker-image.tar

      - name: Upload patient Docker image artifact
        uses: actions/upload-artifact@v4
        with:
          name: patient-docker-image
          path: patient-docker-image.tar

      - name: Upload doctor Docker image artifact
        uses: actions/upload-artifact@v4
        with:
          name: doctor-docker-image
          path: doctor-docker-image.tar

  # JOB 4 : Analyse de vuln√©rabilit√©s des images avec Trivy
  image-scan:
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download patient Docker image
        uses: actions/download-artifact@v4
        with:
          name: patient-docker-image
          path: .

      - name: Download doctor Docker image
        uses: actions/download-artifact@v4
        with:
          name: doctor-docker-image
          path: .

      - name: Load images to local Docker
        run: |
          docker load < patient-docker-image.tar
          docker load < doctor-docker-image.tar

      - name: Trivy scan patient-service
        run: |
          mkdir -p reports
          docker run --rm -v $(pwd):/reports aquasec/trivy:latest image patient-local:latest --format json --output /reports/trivy-patient-report.json --severity HIGH,CRITICAL || true
          [ -s reports/trivy-patient-report.json ] || echo "[]" > reports/trivy-patient-report.json

      - name: Trivy scan doctor-service
        run: |
          mkdir -p reports
          docker run --rm -v $(pwd):/reports aquasec/trivy:latest image doctor-local:latest --format json --output /reports/trivy-doctor-report.json --severity HIGH,CRITICAL || true
          [ -s reports/trivy-doctor-report.json ] || echo "[]" > reports/trivy-doctor-report.json

      - name: Check Trivy results for patient-service
        run: |
          if [ -f trivy-patient-report.json ]; then
            cat trivy-patient-report.json
            CRITICAL=$(jq '[.[]?.Vulnerabilities[]? | select(.Severity=="CRITICAL")] | length' trivy-patient-report.json || echo 0)
            echo "CRITICAL vulns in patient-service: $CRITICAL"
            if [ "$CRITICAL" -gt 0 ]; then
              echo "‚ùå CRITICAL vulnerabilities detected in patient-service. Failing pipeline."
              exit 1
            fi
          fi

      - name: Check Trivy results for doctor-service
        run: |
          if [ -f trivy-doctor-report.json ]; then
            cat trivy-doctor-report.json
            CRITICAL=$(jq '[.[]?.Vulnerabilities[]? | select(.Severity=="CRITICAL")] | length' trivy-doctor-report.json || echo 0)
            echo "CRITICAL vulns in doctor-service: $CRITICAL"
            if [ "$CRITICAL" -gt 0 ]; then
              echo "‚ùå CRITICAL vulnerabilities detected in doctor-service. Failing pipeline."
              exit 1
            fi
          fi

      - name: Upload Trivy reports
        uses: actions/upload-artifact@v4
        with:
          name: trivy-reports
          path: reports/trivy-*-report.json
        if: always()

  # JOB 5 : Publication des images vers GHCR
  push:
    runs-on: ubuntu-latest
    needs: image-scan
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    permissions:
      packages: write
      contents: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: .

      - name: Load and Tag images
        run: |
          docker load < patient-docker-image/patient-docker-image.tar
          docker load < doctor-docker-image/doctor-docker-image.tar
          docker tag patient-local:latest ${{ env.IMAGE_TAG_PATIENT }}
          docker tag doctor-local:latest ${{ env.IMAGE_TAG_DOCTOR }}

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GHCR_PAT }}

      - name: Push images
        run: |
          docker push ${{ env.IMAGE_TAG_PATIENT }}
          docker push ${{ env.IMAGE_TAG_DOCTOR }}

  # JOB 6 : D√©ploiement Staging via Ansible
  deploy-to-staging:
    runs-on: ubuntu-latest
    needs: push
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    environment: staging
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Setup SSH key for Ansible
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.MASTER_NODE_SSH_KEY }}" > ~/.ssh/master.pem
          chmod 600 ~/.ssh/master.pem
          ssh-keyscan -H 174.129.231.212 >> ~/.ssh/known_hosts 2>/dev/null || true
          ssh-keyscan -H 3.217.37.12 >> ~/.ssh/known_hosts 2>/dev/null || true

      - name: Install Ansible & dependencies
        run: |
          pip install ansible kubernetes
          ansible --version

      - name: Configure kubeconfig
        env:
          KUBECONFIG_DATA: ${{ secrets.KUBECONFIG_DATA }}
        run: |
          mkdir -p ~/.kube
          echo "$KUBECONFIG_DATA" | base64 -d > ~/.kube/config
          kubectl cluster-info

      - name: Create staging namespace and pull secret
        run: |
          kubectl create namespace ${{ env.STAGING_NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -
          kubectl delete secret ghcr-secret -n ${{ env.STAGING_NAMESPACE }} --ignore-not-found
          kubectl create secret docker-registry ghcr-secret \
            --namespace=${{ env.STAGING_NAMESPACE }} \
            --docker-server=ghcr.io \
            --docker-username=${{ github.actor }} \
            --docker-password=${{ secrets.GHCR_PAT }}

      - name: Deploy to staging via Ansible
        working-directory: ansible
        env:
          IMAGE_TAG_PATIENT: ${{ env.IMAGE_TAG_PATIENT }}
          IMAGE_TAG_DOCTOR: ${{ env.IMAGE_TAG_DOCTOR }}
          NODE_PORT_PATIENT: ${{ env.NODE_PORT_STAGING_PATIENT }}
          NODE_PORT_DOCTOR: ${{ env.NODE_PORT_STAGING_DOCTOR }}
          KUBECONFIG: ~/.kube/config
          namespace: ${{ env.STAGING_NAMESPACE }}
        run: |
          ansible-playbook playbooks/deploy-medinsight.yml \
            -e "env=staging" \
            -e "image_tag_doctor=${{ env.IMAGE_TAG_DOCTOR }}" \
            -e "image_tag_patient=${{ env.IMAGE_TAG_PATIENT }}"

  # JOB 7 : V√©rification Sant√© via Ansible
  ansible-health-check:
    runs-on: ubuntu-latest
    needs: deploy-to-staging
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python and Ansible
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Setup kubeconfig
        env:
          KUBECONFIG_DATA: ${{ secrets.KUBECONFIG_DATA }}
        run: |
          mkdir -p ~/.kube
          echo "$KUBECONFIG_DATA" | base64 -d > ~/.kube/config
          chmod 600 ~/.kube/config

      - name: Run Ansible Health Check
        working-directory: ansible
        run: |
          pip install ansible kubernetes
          ansible-playbook playbooks/check-cluster-health.yml -e kubeconfig_path=/home/runner/.kube/config

      - name: Upload health report
        uses: actions/upload-artifact@v4
        with:
          name: health-report-${{ github.run_number }}
          path: ansible/reports/
        if: always()

  # JOB 8 : Scan Dynamique (DAST) avec OWASP ZAP
  security-scan:
    runs-on: ubuntu-latest
    needs: deploy-to-staging
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure kubeconfig
        env:
          KUBECONFIG_DATA: ${{ secrets.KUBECONFIG_DATA }}
        run: |
          mkdir -p ~/.kube
          echo "$KUBECONFIG_DATA" | base64 -d > ~/.kube/config

      - name: Port forward and run OWASP ZAP scan
        run: |
          kubectl port-forward -n ${{ env.STAGING_NAMESPACE }} svc/patient-service 8080:${{ env.APP_PORT_PATIENT }} &
          FORWARD_PID=$!
          sleep 5
          docker run --rm --network host -v $(pwd):/zap/wrk/:rw \
            ghcr.io/zaproxy/zaproxy:stable zap-baseline.py \
            -t "http://localhost:8080" -m 10 -r zap_report.html -J zap_report.json || true
          kill $FORWARD_PID || true
          [ -s zap_report.html ] || echo "<html><body>No report generated</body></html>" > zap_report.html
          [ -s zap_report.json ] || echo "{}" > zap_report.json

      - name: Upload ZAP reports
        uses: actions/upload-artifact@v4
        with:
          name: zap-reports
          path: zap_report.*
        if: always()

  # JOB 9 : Promotion en Production (D√©ploiement final)
  promote-to-prod:
    runs-on: ubuntu-latest
    needs: security-scan
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    environment: production
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure kubeconfig
        env:
          KUBECONFIG_DATA: ${{ secrets.KUBECONFIG_DATA }}
        run: |
          mkdir -p ~/.kube
          echo "$KUBECONFIG_DATA" | base64 -d > ~/.kube/config

      - name: Create prod namespace and secret
        run: |
          kubectl create namespace ${{ env.PROD_NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -
          kubectl delete secret ghcr-secret -n ${{ env.PROD_NAMESPACE }} --ignore-not-found
          kubectl create secret docker-registry ghcr-secret \
            --namespace=${{ env.PROD_NAMESPACE }} \
            --docker-server=ghcr.io \
            --docker-username=${{ github.actor }} \
            --docker-password=${{ secrets.GHCR_PAT }}

      - name: Setup Ansible Environment
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Setup SSH key for Ansible
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.MASTER_NODE_SSH_KEY }}" > ~/.ssh/master.pem
          chmod 600 ~/.ssh/master.pem
          ssh-keyscan -H 174.129.231.212 >> ~/.ssh/known_hosts 2>/dev/null || true
          ssh-keyscan -H 3.217.37.12 >> ~/.ssh/known_hosts 2>/dev/null || true

      - name: Deploy to production via Ansible
        working-directory: ansible
        env:
          IMAGE_TAG_PATIENT: ${{ env.IMAGE_TAG_PATIENT }}
          IMAGE_TAG_DOCTOR: ${{ env.IMAGE_TAG_DOCTOR }}
          NODE_PORT_PATIENT: ${{ env.NODE_PORT_PROD_PATIENT }}
          NODE_PORT_DOCTOR: ${{ env.NODE_PORT_PROD_DOCTOR }}
          KUBECONFIG: ~/.kube/config
          namespace: ${{ env.PROD_NAMESPACE }}
        run: |
          pip install ansible kubernetes
          ansible-playbook playbooks/deploy-medinsight.yml \
            -e "env=prod" \
            -e "image_tag_doctor=${{ env.IMAGE_TAG_DOCTOR }}" \
            -e "image_tag_patient=${{ env.IMAGE_TAG_PATIENT }}"